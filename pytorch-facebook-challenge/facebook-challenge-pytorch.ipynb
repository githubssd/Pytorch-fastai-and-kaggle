{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "%load_ext autoreload\n%autoreload 2\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "84f27908e4a6ee71d32b7b089a346c468e7bbd41"
      },
      "cell_type": "code",
      "source": "trn_path= '../input/flower_data/flower_data/train'\nvld_path= '../input/flower_data/flower_data/valid'\n\n# TODO: Define transforms for the training data and testing data\ntrain_transforms = transforms.Compose([transforms.RandomRotation(30),\n                                       transforms.RandomResizedCrop(224),\n                                       transforms.RandomHorizontalFlip(),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize([0.485, 0.456, 0.406],\n                                                            [0.229, 0.224, 0.225])])\n\ntest_transforms = transforms.Compose([transforms.Resize(255),\n                                      transforms.CenterCrop(224),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize([0.485, 0.456, 0.406],\n                                                           [0.229, 0.224, 0.225])])\n\n# Pass transforms in here, then run the next cell to see how the transforms look\ntrain_data = datasets.ImageFolder(trn_path, transform=train_transforms)\ntest_data =  datasets.ImageFolder(vld_path, transform=test_transforms)\n\ntrainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\ntestloader = torch.utils.data.DataLoader(test_data, batch_size=64)",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e014ed4e87dc408cbc539238d2f2207bc7c1ca97"
      },
      "cell_type": "code",
      "source": "model = models.resnet152(pretrained=True)",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /tmp/.torch/models/resnet152-b121ed2d.pth\n100%|██████████| 241530880/241530880 [00:03<00:00, 75091438.13it/s]\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "da62fce70f814a275b6484024acfaec64a9d20fa"
      },
      "cell_type": "code",
      "source": "# Freeze parameters so we don't backprop through them\nfor param in model.parameters():\n    param.requires_grad = False\n\nfrom collections import OrderedDict\nclassifier = nn.Sequential(OrderedDict([\n                          ('fc1', nn.Linear(2048, 500)),\n                          ('relu', nn.Dropout(0.2)),\n                          ('relu', nn.ReLU()),\n                          ('fc2', nn.Linear(500, 102)),\n                          ('output', nn.LogSoftmax(dim=1))\n                          ]))\n    \nmodel.fc = classifier",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e1b2f607bd8d1a415f2c165a818a85febdfdea23"
      },
      "cell_type": "code",
      "source": "from torch.optim import lr_scheduler\n# Use GPU if it's available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\n# Only train the classifier parameters, feature parameters are frozen\noptimizer = optim.Adam(model.fc.parameters(), lr=0.003)\ncriterion = nn.CrossEntropyLoss()\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.3)\nmodel.to(device)\ncriterion = criterion.cuda()",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "94a52c638051440e8238e9c635a473f84534249a"
      },
      "cell_type": "code",
      "source": "import numpy as np\n# number of epochs to train the model\nn_epochs = 14\ntrain_on_gpu = True\nvalid_loss_min = np.Inf # track change in validation loss\n\nfor epoch in range(1, n_epochs+1):\n\n    # keep track of training and validation loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    accuracy = 0.0\n    ###################\n    # train the model #\n    ###################\n    model.train()\n    exp_lr_scheduler.step()\n    for batch_idx, (data, target) in enumerate(trainloader):\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update training loss\n        train_loss += loss.item()*data.size(0)\n        \n    ######################    \n    # validate the model #\n    ######################\n    model.eval()\n    for batch_idx, (data, target) in enumerate(testloader):\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # update average validation loss \n        valid_loss += loss.item()*data.size(0)\n        ps = torch.exp(output)\n        top_p, top_class = ps.topk(1, dim=1)\n        equals = top_class == target.view(*top_class.shape)\n        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n    \n    # calculate average losses\n    train_loss = train_loss/len(trainloader.dataset)\n    valid_loss = valid_loss/len(testloader.dataset)\n    accuracy  = accuracy/len(testloader)\n        \n    # print training/validation statistics \n    print('Epoch: {} \\tTrain_Loss: {:.6f} \\tVali_Loss: {:.6f} \\tValid_accuracy: {:.6f}'.format(\n        epoch, train_loss, valid_loss, accuracy))\n    \n    # save model if validation loss has decreased\n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(model.state_dict(), 'model_augmented.pt')\n        valid_loss_min = valid_loss",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Epoch: 1 \tTrain_Loss: 2.801837 \tVali_Loss: 1.056292 \tValid_accuracy: 0.696731\nValidation loss decreased (inf --> 1.056292).  Saving model ...\nEpoch: 2 \tTrain_Loss: 1.066743 \tVali_Loss: 0.613693 \tValid_accuracy: 0.838510\nValidation loss decreased (1.056292 --> 0.613693).  Saving model ...\nEpoch: 3 \tTrain_Loss: 0.754732 \tVali_Loss: 0.436781 \tValid_accuracy: 0.884519\nValidation loss decreased (0.613693 --> 0.436781).  Saving model ...\nEpoch: 4 \tTrain_Loss: 0.536468 \tVali_Loss: 0.322721 \tValid_accuracy: 0.920192\nValidation loss decreased (0.436781 --> 0.322721).  Saving model ...\nEpoch: 5 \tTrain_Loss: 0.493612 \tVali_Loss: 0.282002 \tValid_accuracy: 0.920385\nValidation loss decreased (0.322721 --> 0.282002).  Saving model ...\nEpoch: 6 \tTrain_Loss: 0.467043 \tVali_Loss: 0.290291 \tValid_accuracy: 0.930673\nEpoch: 7 \tTrain_Loss: 0.430702 \tVali_Loss: 0.261588 \tValid_accuracy: 0.932212\nValidation loss decreased (0.282002 --> 0.261588).  Saving model ...\nEpoch: 8 \tTrain_Loss: 0.405851 \tVali_Loss: 0.257229 \tValid_accuracy: 0.935481\nValidation loss decreased (0.261588 --> 0.257229).  Saving model ...\nEpoch: 9 \tTrain_Loss: 0.380381 \tVali_Loss: 0.257428 \tValid_accuracy: 0.933750\nEpoch: 10 \tTrain_Loss: 0.357184 \tVali_Loss: 0.250561 \tValid_accuracy: 0.946635\nValidation loss decreased (0.257229 --> 0.250561).  Saving model ...\nEpoch: 11 \tTrain_Loss: 0.362873 \tVali_Loss: 0.245672 \tValid_accuracy: 0.936683\nValidation loss decreased (0.250561 --> 0.245672).  Saving model ...\nEpoch: 12 \tTrain_Loss: 0.367369 \tVali_Loss: 0.248930 \tValid_accuracy: 0.936683\nEpoch: 13 \tTrain_Loss: 0.383762 \tVali_Loss: 0.250888 \tValid_accuracy: 0.943365\nEpoch: 14 \tTrain_Loss: 0.363050 \tVali_Loss: 0.244172 \tValid_accuracy: 0.940288\nValidation loss decreased (0.245672 --> 0.244172).  Saving model ...\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "de4518933d775c5f9defaf6cf1030d95d24644c6"
      },
      "cell_type": "code",
      "source": "for param in model.parameters():\n    param.requires_grad = True\n\n\noptimizer = optim.Adam(model.parameters(), lr=1e-5)#optimizer = torch.optim.SGD([{'params': model.parameters()}], lr=1e-5)\n\n\n\nmodel.to(device)\ncriterion = criterion.cuda()",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b950d7b9f0cc3c93601c00165cfd07c067109a9b"
      },
      "cell_type": "code",
      "source": "trainloader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)\ntestloader = torch.utils.data.DataLoader(test_data, batch_size=8)",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eee94065041f1487a5249f2639a9c26d330aadcb"
      },
      "cell_type": "code",
      "source": "import numpy as np\n# number of epochs to train the model\nn_epochs = 10\ntrain_on_gpu = True\n\nfor epoch in range(1, n_epochs+1):\n\n    # keep track of training and validation loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    accuracy = 0.0\n    ###################\n    # train the model #\n    ###################\n    model.train()\n    exp_lr_scheduler.step()\n    for batch_idx, (data, target) in enumerate(trainloader):\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update training loss\n        train_loss += loss.item()*data.size(0)\n        \n    ######################    \n    # validate the model #\n    ######################\n    model.eval()\n    for batch_idx, (data, target) in enumerate(testloader):\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # update average validation loss \n        valid_loss += loss.item()*data.size(0)\n        ps = torch.exp(output)\n        top_p, top_class = ps.topk(1, dim=1)\n        equals = top_class == target.view(*top_class.shape)\n        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n    \n    # calculate average losses\n    train_loss = train_loss/len(trainloader.dataset)\n    valid_loss = valid_loss/len(testloader.dataset)\n    accuracy  = accuracy/len(testloader)\n        \n    # print training/validation statistics \n    print('Epoch: {} \\tTrain_Loss: {:.6f} \\tVali_Loss: {:.6f} \\tValid_accuracy: {:.6f}'.format(\n        epoch, train_loss, valid_loss, accuracy))\n    \n    # save model if validation loss has decreased\n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(model.state_dict(), 'model_augmented.pt')\n        valid_loss_min = valid_loss",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Epoch: 1 \tTrain_Loss: 0.555060 \tVali_Loss: 0.192836 \tValid_accuracy: 0.951456\nValidation loss decreased (0.244172 --> 0.192836).  Saving model ...\nEpoch: 2 \tTrain_Loss: 0.431984 \tVali_Loss: 0.156842 \tValid_accuracy: 0.968447\nValidation loss decreased (0.192836 --> 0.156842).  Saving model ...\nEpoch: 3 \tTrain_Loss: 0.356984 \tVali_Loss: 0.138099 \tValid_accuracy: 0.968447\nValidation loss decreased (0.156842 --> 0.138099).  Saving model ...\nEpoch: 4 \tTrain_Loss: 0.308121 \tVali_Loss: 0.118345 \tValid_accuracy: 0.976942\nValidation loss decreased (0.138099 --> 0.118345).  Saving model ...\nEpoch: 5 \tTrain_Loss: 0.273416 \tVali_Loss: 0.122006 \tValid_accuracy: 0.972087\nEpoch: 6 \tTrain_Loss: 0.266815 \tVali_Loss: 0.099462 \tValid_accuracy: 0.974515\nValidation loss decreased (0.118345 --> 0.099462).  Saving model ...\nEpoch: 7 \tTrain_Loss: 0.235720 \tVali_Loss: 0.098314 \tValid_accuracy: 0.974515\nValidation loss decreased (0.099462 --> 0.098314).  Saving model ...\nEpoch: 8 \tTrain_Loss: 0.198014 \tVali_Loss: 0.086215 \tValid_accuracy: 0.978155\nValidation loss decreased (0.098314 --> 0.086215).  Saving model ...\nEpoch: 9 \tTrain_Loss: 0.203693 \tVali_Loss: 0.097070 \tValid_accuracy: 0.973301\nEpoch: 10 \tTrain_Loss: 0.196125 \tVali_Loss: 0.081830 \tValid_accuracy: 0.979369\nValidation loss decreased (0.086215 --> 0.081830).  Saving model ...\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dbcb32c7fccc60be0ca57ad4be5715d2741291ae"
      },
      "cell_type": "code",
      "source": "from IPython.display import FileLink\nFileLink('model_augmented.pt')",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "/kaggle/working/model_augmented.pt",
            "text/html": "<a href='model_augmented.pt' target='_blank'>model_augmented.pt</a><br>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "62f778c81381ef1d7b915b5f2b724be3e13a1540"
      },
      "cell_type": "code",
      "source": "model.load_state_dict( torch.load('model_augmented.pt'))",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "01ab640b35793a1957fe1ee296ff5bc2a074bd4c"
      },
      "cell_type": "code",
      "source": "import numpy as np\n# number of epochs to train the model\nn_epochs = 10\ntrain_on_gpu = True\n\nfor epoch in range(1, n_epochs+1):\n\n    # keep track of training and validation loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    accuracy = 0.0\n    ###################\n    # train the model #\n    ###################\n    model.train()\n    exp_lr_scheduler.step()\n    for batch_idx, (data, target) in enumerate(trainloader):\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n        # update training loss\n        train_loss += loss.item()*data.size(0)\n        \n    ######################    \n    # validate the model #\n    ######################\n    model.eval()\n    for batch_idx, (data, target) in enumerate(testloader):\n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the batch loss\n        loss = criterion(output, target)\n        # update average validation loss \n        valid_loss += loss.item()*data.size(0)\n        ps = torch.exp(output)\n        top_p, top_class = ps.topk(1, dim=1)\n        equals = top_class == target.view(*top_class.shape)\n        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n    \n    # calculate average losses\n    train_loss = train_loss/len(trainloader.dataset)\n    valid_loss = valid_loss/len(testloader.dataset)\n    accuracy  = accuracy/len(testloader)\n        \n    # print training/validation statistics \n    print('Epoch: {} \\tTrain_Loss: {:.6f} \\tVali_Loss: {:.6f} \\tValid_accuracy: {:.6f}'.format(\n        epoch, train_loss, valid_loss, accuracy))\n    \n    # save model if validation loss has decreased\n    if valid_loss <= valid_loss_min:\n        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n        valid_loss_min,\n        valid_loss))\n        torch.save(model.state_dict(), 'model_augmented.pt')\n        valid_loss_min = valid_loss",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Epoch: 1 \tTrain_Loss: 0.175016 \tVali_Loss: 0.079022 \tValid_accuracy: 0.985437\nValidation loss decreased (0.081830 --> 0.079022).  Saving model ...\nEpoch: 2 \tTrain_Loss: 0.174524 \tVali_Loss: 0.098400 \tValid_accuracy: 0.976942\nEpoch: 3 \tTrain_Loss: 0.164452 \tVali_Loss: 0.078287 \tValid_accuracy: 0.983010\nValidation loss decreased (0.079022 --> 0.078287).  Saving model ...\nEpoch: 4 \tTrain_Loss: 0.165037 \tVali_Loss: 0.078096 \tValid_accuracy: 0.983010\nValidation loss decreased (0.078287 --> 0.078096).  Saving model ...\nEpoch: 5 \tTrain_Loss: 0.158797 \tVali_Loss: 0.073990 \tValid_accuracy: 0.985437\nValidation loss decreased (0.078096 --> 0.073990).  Saving model ...\nEpoch: 6 \tTrain_Loss: 0.152567 \tVali_Loss: 0.071091 \tValid_accuracy: 0.989078\nValidation loss decreased (0.073990 --> 0.071091).  Saving model ...\nEpoch: 7 \tTrain_Loss: 0.156323 \tVali_Loss: 0.092374 \tValid_accuracy: 0.979369\nEpoch: 8 \tTrain_Loss: 0.134140 \tVali_Loss: 0.072307 \tValid_accuracy: 0.989078\nEpoch: 9 \tTrain_Loss: 0.137717 \tVali_Loss: 0.075082 \tValid_accuracy: 0.984223\nEpoch: 10 \tTrain_Loss: 0.126323 \tVali_Loss: 0.094924 \tValid_accuracy: 0.976942\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c36ccdbe496add7145d321f115b9a73cfe36dc58"
      },
      "cell_type": "code",
      "source": "FileLink('model_augmented.pt')",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "/kaggle/working/model_augmented.pt",
            "text/html": "<a href='model_augmented.pt' target='_blank'>model_augmented.pt</a><br>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2f1807ace39c569edc6791b2c445fdef6d88541b"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}